{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu49823L791v"
      },
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_in, H, D_out = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")"
      ],
      "metadata": {
        "id": "92Eh3EQ38A1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(torch.randn(64, 784))\n",
        "outputs.shape"
      ],
      "metadata": {
        "id": "o30VLxpm8DO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Size([64, 10])"
      ],
      "metadata": {
        "id": "oXTTNOAo8EsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "U7KD2Tte8GIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sequential(\n",
        "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
        "  (1): ReLU()\n",
        "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
        ")"
      ],
      "metadata": {
        "id": "1ApllTUe8HX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# descarga datos\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, Y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "1oLmgYSg8Ilv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# normalización y split\n",
        "\n",
        "X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., Y[:60000].astype(int), Y[60000:].astype(int)"
      ],
      "metadata": {
        "id": "F05cBbyk8Kh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def cross_entropy(output, target):\n",
        "    logits = output[torch.arange(len(output)), target]\n",
        "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "3VItS87u8M3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convertimos datos a tensores y copiamos en gpu\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy(y_train).long().cuda()\n",
        "\n",
        "# bucle entrenamiento\n",
        "epochs = 100\n",
        "lr = 0.8\n",
        "log_each = 10\n",
        "l = []\n",
        "for e in range(1, epochs+1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = cross_entropy(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= lr * param.grad\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ],
      "metadata": {
        "id": "ew0pJqcM8Pjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "metadata": {
        "id": "X1E37W4x8RDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}